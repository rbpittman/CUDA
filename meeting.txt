Meeting:
---------

I forgot to __syncthreads() before doing the write. Now the simulation doesn't 
change randomly. 
The weird data anomaly occurs when the number of blocks go past a multiple of 8. 
When graphing the Mandelbrot set benchmarks it abbreviates the x axis to 1e7 factors. 
  Is that ok? The other graph does a wierd thing with the zeros. And the fastest
  3 graph on Python shoots off pretty fast. 

TODO:
Analyze what can be said about ratios between python and PyCUDA. 
Write theory section. 
Find more modern paper convention on the graph unit label. 


Meeting:
--------

Wrote a Python program to compute the best fit line. So the ratio
between the slow matrix multiplication and fast is 5.68. 
Ran Python 12 hour bench on matrix multiplication. That's why I
couldn't draw out those ratios yet. 
Found paper that talks about step vs work complexity. 
idea: To keep it simple, what if I analyze performance gain from a
naive implementation of various algorithms, perhaps a classification
based on an estimation of the expected number of read/write accesses
on global memory. 

PLAN:
Find out more about step complexity vs work complexity. 
Planning on writing a program that prints out the difference between
python and pycuda, and c++ and cuda. 

TODO:
Difference between the model for gpu execution paper and the "idea"
mentioned above. 
Backup researchMachine. 


Meeting:
--------
Found another good paper on parallel complexity and that step
complexity vs work complexity. 
REALLY weird stuff going on with the best-power-finder. 
C++Long curve had 1.626 power. It's 1.553 when cut to normal times. 

Diff from the other paper: They are trying more to develop a model
 that allows one to write code to maximize performance by using various
 memory types in the GPU. Mine is developing a way by which a serial
 algorithm's performance boost from the conversion to naive GPU
 parallel algorithm can be modeled simply from the structure of the
 serial algorithm. 

How to write a theory section without knowing what the main objective
is?

Am I doing the 8-queens problem next week?

PLAN:

Draw the graph for the simulator, where the gpu performance is slower
than CPU. 
Do something along the lines of the classification of the number of
global read/writes required to complete a problem as a function of the
input size. 

TODO:
Rewrite schedule for next week.
Calculate total C++Long runtime
google about the operating system setting the priority of the job. 
Maybe set the priority to high. 


Meeting:
--------
Global memory access complexities:
Mandelbrot:  gn
Matrix mult: g*(2n^1.5 + n)
Simulator:   5fg*(n^2 + n), f = number of frames

GPU Speed up ratios:
Mandelbrot:  C++ / CUDA = 5.94510
Matrix Mult: C++ / CUDA = 2.69069
Simulator:   C++ / CUDA = 0.77348

Let's assume that the CPU and GPU algorithm have in common the type of 
arithmetic operations they must do (aside from a few thread index computation
things). Then we can say that the GPU has:
p = threads
n = input size
g = time to execute a global memory read/write

Then the time it takes the CPU to execute a program is proportional to the 
number of operations:
t_cpu = (1 / cpu_flops) * f(n)
where f(n) is a function that gives the number of operations required
to solve the benchmark problem with an input of size n. Presumably,
f(n) is the same for the CPU as for the GPU. 
t_gpu = ((1 / gpu_flops) * f(n) / p) + h(n)g
where gpu_flops is the number of flops that one thread of the gpu can
perform, h(n) is a function of input size n that gives the number of
global memory accesses performed. 

One problem is the values of cpu_flops and gpu_flops. We can find c for:
c = cpu_flops / gpu_flops



Meeting:
--------
Running benchmark, will see in the morning whether the graph is better. 

Try 1:
------

time_gpu(n) = g * h(n) + (c(n) / p)
h(n) is the number of global memory read/writes. 
c(n) is some function of n that gives the time spent on other
numerical calculations. 
p is number of threads. 
This formula only applies for larger values of p. 

time_cpu(n) = x * c(n)
where x is a factor presumably such that x < 1 which means that the
cpu can execute faster than the gpu in terms of general calculations. 

Mandelbrot:
h(n) = n
p = min(768, n)
time_gpu(n) = gn + (c(n) / min(768, n))

Try 2:
------
p = number of threads
time_gpu(n) = c * (time_cpu(n) / p) + g * h(n)

Mandelbrot:
p = min(768, n)
time_gpu(n) = c * (time_cpu(n) / min(768, n)) + gn
Assume a decent number of pixels (larger than 27X27). 
time_gpu(n) = c * (time_cpu(n) / 768) + gn + init_time

--->
The power analysis on the "mean" python turned up the same power. 
--->

--->
Got some weird behavior with the GPU. 
--->


Plan:
-----
Try to find some paper that talks about mathematical models for
parallel computation. Find some equations. 


TODO:
-----

Use an ax^2 + bx + c. bx is the matrix multiplication generation. 
Keep working on testing global memory access. 
Find papers on modeling gpu performance execution. 


Meeting:
--------

Trying to determine the operations relating to global memory that
have n as a factor in the time equation for that operation. 
Figured out how to test the global diff performance. 
Crazy nvcc compiler optimizations:
This runs in O(steps) time:
for(int i = 0; i < steps; i++) {
  c += i;
}

This runs in constant time, still producing the correct result:
for(int i = 0; i < steps; i++) {
  c++;
}

Tried to figure out the equation for the 1.73 curve. No such luck. 


TODO:
-----
Figure out the equation for the memcpy function based on size. 
Using max memcpy size performed, figure out greatest time effect. 



Meeting:
--------
Equation for GPU 1.79931515731e-05 * x^1.0 + 0.142268967261

malloc testing did NOT go well at all! It does weird suballocation 
things that affect the run-time performance. 
Actually, methinks i got it for the worst case. 
Time to allocate and free 10000 times for various sizes has now been measured. 
If I don't free, it keeps using more and more memory. 
It does something weird where if I send in a value that is far to big, 


TODO:
-----
Test cudaMemset and get its complexity. 
Recreate model in more detail including all the types of global memory access. 

PLAN:
-----
Brief look at what particles simulations do for initial velocity. 
